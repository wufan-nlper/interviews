"""
过往百度面试题
1. 给定二维数组，其每行从左到右递增，每列从上到下递增，判断某个数是否在其中
    解法：从右上角开始，若大于目标数，则向左移动，若小于目标数，则向下移动
2. 给定链表，判断是否有环，并找到环的入口
    解法：快慢指针，快指针每次走两步，慢指针每次走一步，若相遇，则有环，再从头开始，快慢指针每次走一步，再次相遇即为环的入口
"""

"""2.7 10点半一面

1. transformer的计算过程？
2. BERT和LLM的区别？
3. 交叉熵的计算细节？
    回答：假定模型预测为x，真实标签为y，交叉熵为 -sum(y * log(x))
4. AUC的含义和计算过程？
    回答：AUC是ROC曲线下的面积，计算过程是将正负样本的预测概率排序，然后计算ROC曲线下的面积
5. 模型训练时，梯度*10和学习率*10有什么区别？
    回答：对于不带动量的优化器（比如SGD），两者是等价的。
        但是对于带动量的优化器（比如Adam），梯度*10会使得动量的影响更大，而学习率*10只是改变了学习率的大小。
        此外，遇到需要梯度裁剪的算法时会有区别，梯度*10会使得梯度裁剪的阈值也变大。
6. 了解多目标学习吗？如何做多目标学习？
    回答：多目标学习是指同时优化多个目标，可以采用加权和的方式，也可以采用多任务学习的方式
7. 你们的知识图谱怎么做的？
    回答：知识图谱是一个大型的图结构，包含实体和关系，可以通过知识图谱进行问答、推理等任务
8. 讲一下Focal loss？
    回答：Focal loss是一种解决类别不平衡问题的损失函数，通过降低易分类样本的权重，提高难分类样本的权重。
        计算公式为：-alpha * (1 - p)^gamma * log(p)
"""

"""0-1背包问题"""
def knapsack(W, wt, val):
    n = len(wt)
    dp = [[0] * (W + 1) for _ in range(n + 1)]
    for i in range(1, n + 1):
        for w in range(1, W + 1):
            if w - wt[i - 1] < 0:
                dp[i][w] = dp[i - 1][w]
            else:
                dp[i][w] = max(dp[i - 1][w], dp[i - 1][w - wt[i - 1]] + val[i - 1])
    return dp[-1][-1]


"""break"""